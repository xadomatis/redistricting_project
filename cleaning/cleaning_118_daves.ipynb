{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data from Dave's Redistricting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to discrepancies in 538's data and untraceable sourcing, I have pulled together public data from Dave's Redistricting App on 3.20.2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the point of initial pull, Missouri and New Hampshire still had incomplete maps. NY and KS were in legal flux, and KY and WV have bad data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, Kentucky and West Virginia, for some reason, did not yet have data for the 2020 Presidential election yet. Ohio's new map was also not included. For these states, we'll still have to use 538's less traceable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the files into a single dataframe\n",
    "path = \"/Users/xavier/Desktop/DSPP/solo_projects/redistricting_project/raw_data/daves_pvis\"\n",
    "all_files = sorted(glob.glob(path + \"/*.csv\"))\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0).reset_index()\n",
    "    df[\"ST\"] = filename[-6:-4]\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cut the frame and fix the columns\n",
    "df = frame[[\"ST\",\"index\",\"Devation\",\"Dem\"]]\n",
    "df.columns = [\"ST\",\"district\",\"dem_pct\",\"gop_pct\"]\n",
    "#remove nonumeric rows\n",
    "possible_numbers = list([str(i) for i in range(53)])\n",
    "df = df[df[\"district\"].isin(possible_numbers)]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 11 states that should be missing:\n",
    "- 3 incomplete maps, FL, NH, MO, with 38 between them\n",
    "- 2 bad data states, KY and WV with 8 between them\n",
    "- 6 single district states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if the # of districts should be 0\n",
    "435-(df.shape[0]+(38+8+6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Dave's data into our standardized format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input standard text values\n",
    "df[\"year\"] = \"2022\"\n",
    "df[\"congress\"] = \"118\"\n",
    "df[\"ST#\"] = df[\"ST\"] + df[\"district\"]\n",
    "#compute metric\n",
    "df[\"raw_metric\"] = (.50 + df[\"gop_pct\"] - .4831) * 100\n",
    "df[\"round_metric\"] = df[\"raw_metric\"].apply(np.around)\n",
    "df[\"metric\"] = round(df[\"raw_metric\"]/100,2)\n",
    "#compute PVI\n",
    "df[\"lean\"] = np.where(df[\"metric\"] > .5, \"R\", \"D\")\n",
    "df['PVI'] = df['lean'] + \"+\" + ((((df['round_metric']-50)).abs())).fillna(1000).astype(int).astype(str)\n",
    "df['PVI'] = df['PVI'].replace(\"D+0\",\"EVEN\")\n",
    "#df['PVI'] = np.where(df['PVI'].str[-1]==\"+\",\"EVEN\",df['PVI'])\n",
    "#df[\"metric\"] = df['PVI'].str.split(\"+\").str[1]\n",
    "#df['metric'] = np.where(df['PVI']==\"EVEN\",\"50\",df['metric'])\n",
    "#df[\"metric\"] = df[\"metric\"].astype(int)\n",
    "#df[\"metric\"] = np.where(df[\"lean\"]==\"D\", (df[\"metric\"]/100))\n",
    "#checker = df[[\"raw_metric\",\"round_metric\",\"metric\",\"PVI\"]]\n",
    "#checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[abs(df[\"round_metric\"] - df[\"raw_metric\"]) > .4]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a clean version of the data to match other outputs\n",
    "pvi_118 = df[[\"year\",\"congress\",\"ST\",\"ST#\",\"PVI\",\"metric\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in 538 Data to fill in gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in filepaths for 538's data\n",
    "path_538 = \"/Users/xavier/Desktop/DSPP/solo_projects/redistricting_project/clean_data/supplimental/data_118_538.csv\"\n",
    "path_pre = \"/Users/xavier/Desktop/DSPP/solo_projects/redistricting_project/clean_data/supplimental/previews_118.csv\"\n",
    "path_st =  \"/Users/xavier/Desktop/DSPP/solo_projects/redistricting_project/clean_data/state_pvi/state_118.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab states with maps not available in Dave's\n",
    "no_data_states = [\"KY\",\"WV\"]\n",
    "load_538 = pd.read_csv(path_538)\n",
    "no_data_rows = load_538[load_538[\"ST\"].isin(no_data_states)]\n",
    "#pull in maps not yet passed\n",
    "pre_rows = pd.read_csv(path_pre)\n",
    "#pull in single states\n",
    "state_118 = pd.read_csv(path_st)\n",
    "#extract the Single District States\n",
    "sds = [\"VT\", \"DE\", \"WY\", \"ND\", \"SD\", \"AK\"]\n",
    "sds_rows = state_118[state_118[\"ST\"].isin(sds)]\n",
    "sds_rows = sds_rows.drop(columns=\"year\")\n",
    "sds_rows[\"ST#\"] =  sds_rows[\"ST\"] + \"AL\"\n",
    "sds_rows[\"lean\"] = np.where(sds_rows[\"ST\"].isin([\"DE\",\"VT\"]), \"D\",\"R\")\n",
    "sds_rows[\"year\"] = 2022\n",
    "sds_rows[\"congress\"] = 118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DE', 'FL', 'GA', 'HI',\n",
       "       'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME', 'MI',\n",
       "       'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM', 'NV',\n",
       "       'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT',\n",
       "       'VA', 'VT', 'WA', 'WI', 'WV', 'WY'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvi_118 = pd.concat([pvi_118,no_data_rows,pre_rows,sds_rows]).sort_values(\"ST\")\n",
    "print(pvi_118.shape)\n",
    "pvi_118.ST.unique()\n",
    "#MD and OH excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 7)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "print(pvi_118.shape)\n",
    "print(pvi_118.ST.unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have something to represent all 435 Districts, we can export a dataset with the best possible estimates of what the 2022 map will look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvi_118.to_csv(\"/Users/xavier/Desktop/DSPP/solo_projects/redistricting_project/clean_data/full_districts/data_118.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>congress</th>\n",
       "      <th>ST</th>\n",
       "      <th>ST#</th>\n",
       "      <th>PVI</th>\n",
       "      <th>metric</th>\n",
       "      <th>lean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [year, congress, ST, ST#, PVI, metric, lean]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvi_118[pvi_118[\"metric\"].isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
